{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61337951",
   "metadata": {},
   "source": [
    "#  EPA-122A *Spatial* Data Science\n",
    "\n",
    "\n",
    "## Assignment 2: Geographic Visualisation\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0813317",
   "metadata": {},
   "source": [
    "# ``Instructions``\n",
    "\n",
    "This assignment puts together what you learned in **Weeks 3-4**. Assignment 3 will build upon what you do in Assignment 2.\n",
    "\n",
    "_Note:_ Go through **labs and homeworks 03-04** before starting this assignment.\n",
    "\n",
    "#### 1.1 Submission\n",
    "\n",
    "Please submit the results by Brightspace under **Assignment 02**, using a single file as example,\n",
    "\n",
    "```text\n",
    "firstname_secondname_thirdname_lastname_02.html\n",
    "\n",
    "```\n",
    "\n",
    "**If your file is not named in lowercase letters as mentioned above, your assignment will not be read by the script that works to compile 200 assignments and you will miss out on the grades. I don't want that, so be exceptionally careful that you name it properly. Don't worry if you spelled your name incorrectly. I want to avoid a situation where I have 200 assignments all called assignment_02.html**\n",
    "\n",
    "Please **do not** submit any data or files other than the ``html file``.\n",
    "\n",
    "Don't worry about your submission _rendering without the images_ **after** you submitted the file on brightspace. That is a brigthspace related issue of viewing your own submission but when I download all assignments as a batch file, I get all your images and code as you intended to submit. So make sure that your html shows everything you want us to see **before you submit**.\n",
    "\n",
    "#### 1.2 How do you convert to HTML?\n",
    "\n",
    "There are 2 ways,\n",
    "\n",
    "1. from a running notebook, you can convert it into html by clicking on the file tab on the main menu of Jupyter Lab\n",
    "    * File &rightarrow; Export Notebooks as... &rightarrow; Export Notebook to HTML\n",
    "2. go to terminal or command line and type\n",
    "    * ``jupyter nbconvert --to html <notebook_name>.ipynb  ``\n",
    "\n",
    "#### 1.3 Learning Objectives\n",
    "\n",
    "This assignment is designed to support three different learning objectives. After completing the following exercises you will be able to:\n",
    "\n",
    "* Combine different datasets\n",
    "* Explore and Visualise Geographic data\n",
    "* Plot (graphs, scatter plots, choropleth, etc..) and discuss (observations, outliers or relationships) important information about the data using the `principles of graphical excellence` and `guidelines of exploratory data analysis`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daad78a",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Critical Data Science``\n",
    "\n",
    "Throughout the assignment, we encourage you to critically reflect on your choices during the Data Science process. To help you set-up your Critical Data Science process, we have provided you with a 'Guide on Critical Data Science'. Section 3.2 contains a step-by-step approach with key considerations for each part of the data science process. The guide can be found [here](https://epa122a.github.io/resources_index.html#a-guide-to-critical-data-science). Below, you will find specific questions which you can use to reflect on your data science choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8784b5d",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Problem``\n",
    "\n",
    "`Problem Statement`:\n",
    "- For this assignment you will use the SHRUG (Socioeconomic High-resolution Rural-Urban Geographic) Platform for India to formulate a hypothesis/RQ and conduct an exploratory data analysis.\n",
    "- To formulate the hypothesis, provide at least `two measurements` that may be related to each other (for example: your hypothesis is that areas with `high air pollution` also have relative high `night light pollution`). And explain why? For example, higher night lights pollution entails densification and nighttime activity. This is possible when many people are clustered together for exchnage of goods and services in a city, ultimately leading to more pollution due to use of resources, traffic and mobility, use of water, discharge of pollutants from cars and factories, etc.\n",
    "- Be explicit about how you define these measurements using markdown cells (for example: how do you measure the air pollution, and how do you measure the levels of light pollution during the night?). Do you use variables to proxy any of these effects?\n",
    "- Observe that the measurements have a normative value attached to it (for example: according to your hypothesis, `high levels` of air pollution in an area is of `more` interest). Please do not assume that there is only one normative definition of a certain measurement and skip your reasoning.\n",
    "- On the basis of the hypothesis and its associated measurements, you will conduct some exploratory/spatial data analysis and provide a reflection of how your hypothesis manifests spatially, using maps and other aiding plots.\n",
    "\n",
    "_Note:_ I am not looking for mathematical equations as justification, but you are welcome to also form simple relations and show them in markdown.\n",
    "\n",
    "A formalised example:\n",
    "\n",
    "\n",
    "> I hypothesise that district in India with relatively high air pollution also have high levels of light pollution, due to high levels of [economic activity](https://www.imf.org/en/Publications/fandd/issues/2019/09/satellite-images-at-night-and-economic-growth-yao).\n",
    "\n",
    ">Definitions of metrics:\n",
    ">- I will measure these effects at district level for all variables.\n",
    ">- Surface PM2.5 pollution (estimated annual ground-level fine particulate matter (PM2.5))\n",
    ">- Night time lights (night time luminosity)\n",
    ">- Facebook relative wealth index (measured as an index between 0 and 1). The index is determined by a machine-learning model that collects target variables from traditional survey data spatially linked to features constructed from non-traditional data like high-resolution satellite imagery, data from mobile phone networks, and topographic maps, as well as aggregated and deidentified connectivity data from Facebook. Used in this analysis as a proxy for wealth and economic activity. This is arguably an oversimplification of the concept of inequality but is considered a suitable approximation given the available datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043302a3",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Tasks``\n",
    "\n",
    "For your convenience, the assignment has been divided into the following tasks,\n",
    "\n",
    "**Exercise 1**:\n",
    "1. Formulate a hypothesis for this assignment as explained above in `problem statement`.\n",
    "2. Using a critical data science lens, evaluate your hypothesis and contrast it with your previous assignment (A1). The following questions can be used as guides to carry out this task.\n",
    "    - Were there any design choices you would make differently this time? Why? (Because of data availability/ methodology for using certain columns as a proxy?)\n",
    "    - Explain what your dependent variable is. Explain your choice of independent variables.\n",
    "    - Would you wish to include any variables that are not available? How is the inclusion beneficial for the hypothesis? Are there any variables (proxies) present with which you could replace these missing values?\n",
    "    - Would that have an effect on your outcomes? Think about bias in the data. Explain your reasoning.\n",
    "    - Reflect on any cases in which this hypothesis will be rejected? Why?\n",
    "    - Reflect on cases in which the hypothesis will be falsely rejected or falsely accepted? Think about bias in the data and in your own reasoning.\n",
    "    - Reflect if there are any important perspectives that you are not taking into account by choosing this hypothesis?\n",
    "\n",
    "**Exercise 2**:\n",
    "1. Use two datasets: merge a shapefile and a csv file.\n",
    "2. Clean your data and make it tabular for your own good! (think about weeks 1-2 and assignment 1)\n",
    "4. Carry out an exploratory data analysis (EDA)\n",
    "5. Report on your hypothesis results both in relationships of the variables and spatial manifestation of the outcome.\n",
    "    * Use at least **3 figures** to support your analysis. Think about exploratory data analysis (build data, clean data, explore global/group properties).\n",
    "    * These figures should have followed the principles of graphical excellence. Using markdown, write explicity under **each** figure at least **3 principles of excellence** you have used to make it.\n",
    "    * Create **choropleths** to display **region-specific information** (ex. population, voting choice or jobs availability) together with **some other elements like the sea, canals, centroids, or amenities** (you may try Open Street Maps data - using `osmnx`).\n",
    "    * Be careful with the use of color (and try to be inclusive of color blind people)\n",
    "    * Use **one method** from the lectures to discuss what you observe for your variable(s). Examples below,\n",
    "          * local or global spatial autocorrelation\n",
    "          * network measures\n",
    "          * spatial weights / spatial lag\n",
    "          * binning\n",
    "          * feature scaling, normalisation or standardisation\n",
    "\n",
    "\n",
    "**Exercise 3**:\n",
    "1. Critically reflect on your EDA and visualizations following the questions below.\n",
    "    - Do they show the relevant information in a precise manner or is the data skewed or biased due to certain choices that you have made in the EDA?\n",
    "    - Could they be further reduced/enhanced? (Refer/Use [Critical Data Science Handbook](https://epa122a.github.io/resources_index.html#a-guide-to-critical-data-science) where needed)\n",
    "\n",
    "***Remember to always document your code! Justify everything you do (cleaning data, analysisng data, exploring data, defining hypothesis or measurements, etc.) using markdown cells as you go through the notebook.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9515d",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Data``\n",
    "\n",
    "Information about the SHRUG can be found [here](https://docs.devdatalab.org/). On this [website](https://www.devdatalab.org/shrug_download/) you can download data for your variables of interest (in csv format) and the shapefiles that you can use for mapping the variables. Put the data in a convenient location on your computer or laptop, ideally in a folder called **data** which is next to this **jupyter notebook**. Make sure you’ve set your working directory in the [correct manner](https://www.delftstack.com/howto/python/relative-path-in-python/).\n",
    "\n",
    "These are a big files and it may take a while to load onto your laptop and into Python (running on the jupyter labs environment).\n",
    "\n",
    "As mentioned above in the problem introduction, you will use at least two datasets.\n",
    "\n",
    "1. **First Dataset:** Download Shapefiles of SHRUG for the geographic level of your assignment (shrid, district, subdistrict)\n",
    "2. **Second Dataset:** Get a second dataset of your choice in SHRUG using the links above (curate this dataset as you like)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adeec01",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Start your analysis``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39514cfd-9812-4535-9701-00fd14a15390",
   "metadata": {},
   "source": [
    "### Hypothesis on Corruption in Rural Constituencies\n",
    "\n",
    "I hypothesize that rural constituencies with a higher prevalence of criminal charges against elected representatives exhibit lower levels of public service delivery, indicative of mismanagement and corruption, while accounting for geographic challenges and socioeconomic disparities.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Corruption Proxy**\n",
    "- `mean_num_crim`: Average number of criminal charges against elected representatives → *Reflects governance quality and potential corruption.*\n",
    "\n",
    "---\n",
    "\n",
    "##### **Public Service Delivery**\n",
    "- `pc11_vd_power_all`: Power Supply For All Users [0 or 1] → *Measures accessibility and reliability of basic utilities, indicating public infrastructure quality.*\n",
    "- `pc11_vd_wat_tap_trt`: Access to treated tap water [0 or 1] → *Captures access to clean drinking water, a key sanitation and health service.*\n",
    "- `pc11_vd_rd_all_wthr`: Roads that are all-weather [0 or 1]. → *Proxy to indicate better infrastructure service*\n",
    "\n",
    "---\n",
    "\n",
    "##### **Control Variables**\n",
    "- **Wealth Index**\n",
    "  - `facebook_mean_rwi`**: Mean relative wealth index → *Reflects wealth distribution and economic disparity across constituencies.*\n",
    "- **Terrain Ruggedness**\n",
    "  - `tri_mean`: Mean terrain ruggedness index → *Captures geographic challenges that may affect infrastructure development and service delivery.*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Unfortunately, the binary design of public service delivery variables, such as access to electricity or treated water, simplifies complex realities into a \"yes\" or \"no\" framework. This overlooks important aspects like quality or sufficiency. For example, having electricity might not mean reliable power supply, leading to misunderstandings about actual service levels. Analyzing each variable separately also makes it harder to see overall service delivery patterns.\n",
    "\n",
    "To address this, the binary variables are combined into a **public service index**, representing the proportion of services available in each constituency. This simplification improves analysis but assumes all services are equally important, which may not reflect their actual impact (e.g., clean water vs. electricity). The **dependent variable** is this composite index. The **independent variable**, `mean_num_crim`, serves as a proxy for corruption, assuming more criminal charges indicate weaker governance. **Control variables** like terrain ruggedness (`tri_mean`), population size, and wealth index (`facebook_mean_rwi`) account for geographic and socioeconomic factors that also influence service delivery.\n",
    "\n",
    "##### **Missing Variables and Proxies**\n",
    "Key missing variables include:\n",
    "- **Public Budget Allocation:** A direct measure of service investment.\n",
    "- **Poverty Rate:** A more specific indicator of economic hardship.\n",
    "- **Service Quality Metrics:** Measures of reliability or adequacy.\n",
    "\n",
    "Proxies like the wealth index and binary access indicators partially address these gaps, but their limitations may bias outcomes. Missing data risks overstating corruption’s role if service delivery depends more on unmeasured factors, like regional policies or historical investments.\n",
    "\n",
    "##### **Hypothesis Rejection and Bias**\n",
    "The hypothesis could be rejected if service delivery is driven more by factors like regional policies, funding, or terrain ruggedness than by corruption. Additionally, rejection may occur if there are significant **time-related effects** not captured in the analysis, such as gradual improvements in service delivery due to long-term investments or reforms that mask the immediate impact of corruption. False rejection might occur if `mean_num_crim` poorly represents actual corruption, while false acceptance could result from unmeasured confounders, like state policies or funding patterns, creating spurious correlations.\n",
    "\n",
    "\n",
    "##### **Conclusion**\n",
    "The binary design simplifies the analysis but has limitations that the composite index only partially addresses. Including variables like public budgets or service quality metrics and accounting for temporal and cultural factors would improve accuracy and provide a more correct understanding of public service delivery in rural constituencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59111e-441e-4cdb-9a71-dd721ffbad0f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "992a5a0e-121f-4714-928a-16ed46af1dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcb949b1-65bc-4551-b639-d3cb7de380de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(file_path, relevant_columns, merge_key):\n",
    "    \"\"\"\n",
    "    Function to process a single dataset, keeping only the relevant columns and ensuring the merge key is included.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        relevant_columns (list): List of columns to retain from the dataset.\n",
    "        merge_key (str): Column to use as the common key for merging datasets.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered dataframe with relevant columns and the merge key.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(\"data/\" + file_path)\n",
    "        \n",
    "        # Add merge key to the relevant columns if it's not already included\n",
    "        if merge_key not in relevant_columns:\n",
    "            relevant_columns = [merge_key] + relevant_columns\n",
    "        \n",
    "        # Filter the relevant columns\n",
    "        filtered_df = df[relevant_columns]\n",
    "        return filtered_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7b1a4ad-3cdb-4654-a1b3-b4ea3cf0a7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ac08_id</th>\n",
       "      <th>year</th>\n",
       "      <th>mean_num_crim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-001</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-001</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-002</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-002</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-003</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ac08_id    year  mean_num_crim\n",
       "0  2008-01-001  2008.0       0.000000\n",
       "1  2008-01-001  2014.0       0.000000\n",
       "2  2008-01-002  2008.0       0.066667\n",
       "3  2008-01-002  2014.0       0.000000\n",
       "4  2008-01-003  2008.0       0.200000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Criminal Charges of Politicians:\n",
    "Measuring the extent of criminal charges among politicians as a direct indicator of corruption.\n",
    "- `mean_num_crim`: Average number of criminal charges against elected representatives \n",
    "\n",
    "source: affidavits_ac\n",
    "\"\"\"\n",
    "\n",
    "criminal_dataset = process_dataset('affidavits_ac.csv', ['year', 'mean_num_crim'], 'ac08_id')\n",
    "\n",
    "criminal_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a5d4267-5955-4a2d-a71f-84bcd063e389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. nan  0.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Public service delivery\n",
    "Measuring the availability of basic utilities such as electricity and treated water, which may indicate governance quality.\n",
    "- pc11_vd_power_all: Power Supply For All Users\n",
    "- pc11_vd_wat_tap_trt: Percentage of households with access to treated tap water.\n",
    "- pc11_vd_rd_all_wthr: Proportion of roads that are all-weather (indicating better infrastructure quality).\n",
    "\n",
    "source: pc11_vd_clean_con08\n",
    "\"\"\"\n",
    "\n",
    "public_delivery_service = process_dataset('pc11_vd_clean_con08.csv', ['pc11_vd_power_dom', 'pc11_vd_wat_tap_trt', 'pc11_vd_rd_all_wthr'], 'ac08_id')\n",
    "\n",
    "public_delivery_service.head(50)\n",
    "\n",
    "unique_values = public_delivery_service['pc11_vd_power_dom'].unique()\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "163c744e-3b33-4280-b47d-732d5468cfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ac08_id</th>\n",
       "      <th>facebook_mean_rwi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-001</td>\n",
       "      <td>-0.203812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-002</td>\n",
       "      <td>0.065980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-003</td>\n",
       "      <td>-0.072646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-004</td>\n",
       "      <td>0.123039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-005</td>\n",
       "      <td>0.300398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ac08_id  facebook_mean_rwi\n",
       "0  2008-01-001          -0.203812\n",
       "1  2008-01-002           0.065980\n",
       "2  2008-01-003          -0.072646\n",
       "3  2008-01-004           0.123039\n",
       "4  2008-01-005           0.300398"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Wealth Disparity:\n",
    "Measuring the distribution of wealth within a region and disparities that might arise due to corruption.\n",
    "- facebook_mean_rwi: Mean relative wealth index of a region.\n",
    "\n",
    "source: facebook_rwi_con08\n",
    "\"\"\"\n",
    "\n",
    "wealth_disparity_dataset = process_dataset('facebook_rwi_con08.csv', ['facebook_mean_rwi'], 'ac08_id')\n",
    "\n",
    "wealth_disparity_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29d56818-f0e5-42c9-b07d-99887ade97a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file terrain_ruggedness.csv: [Errno 2] No such file or directory: 'data/terrain_ruggedness.csv'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m terrain_ruggedness_dataset \u001b[38;5;241m=\u001b[39m process_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mterrain_ruggedness.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtri_mean\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mac08_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the dataset\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mterrain_ruggedness_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Terrain Ruggedness:\n",
    "Analyzing terrain ruggedness as a geographic barrier that may influence access to public services and infrastructure.\n",
    "- tri_mean: Mean terrain ruggedness index, representing geographic challenges within regions.\n",
    "\n",
    "Source:\n",
    "- Terrain Ruggedness: terrain_ruggedness.csv\n",
    "\"\"\"\n",
    "\n",
    "# Load terrain ruggedness dataset\n",
    "terrain_ruggedness_dataset = process_dataset('terrain_ruggedness.csv', ['tri_mean'], 'ac08_id')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "terrain_ruggedness_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63c836-f575-40f7-b7ab-629a9fd3ece3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a5460ab-ace7-423a-963f-3849805a5e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 4182 entries, 0 to 4181\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   OBJECTID    4182 non-null   int32   \n",
      " 1   ST_CODE     4182 non-null   int64   \n",
      " 2   ST_NAME     4182 non-null   object  \n",
      " 3   DT_CODE     4112 non-null   float64 \n",
      " 4   DIST_NAME   4110 non-null   object  \n",
      " 5   AC_NO       4182 non-null   int64   \n",
      " 6   AC_NAME     4148 non-null   object  \n",
      " 7   PC_NO       4182 non-null   int64   \n",
      " 8   PC_NAME     4148 non-null   object  \n",
      " 9   PC_ID       4182 non-null   int64   \n",
      " 10  STATUS      524 non-null    object  \n",
      " 11  Shape_Leng  4182 non-null   float64 \n",
      " 12  Shape_Area  4182 non-null   float64 \n",
      " 13  geometry    4182 non-null   geometry\n",
      "dtypes: float64(3), geometry(1), int32(1), int64(4), object(5)\n",
      "memory usage: 441.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>ST_CODE</th>\n",
       "      <th>ST_NAME</th>\n",
       "      <th>DT_CODE</th>\n",
       "      <th>DIST_NAME</th>\n",
       "      <th>AC_NO</th>\n",
       "      <th>AC_NAME</th>\n",
       "      <th>PC_NO</th>\n",
       "      <th>PC_NAME</th>\n",
       "      <th>PC_ID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>NAGALAND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MON</td>\n",
       "      <td>41</td>\n",
       "      <td>Tizit</td>\n",
       "      <td>1</td>\n",
       "      <td>NAGALAND</td>\n",
       "      <td>1301</td>\n",
       "      <td>Pre delimitation</td>\n",
       "      <td>1.381854</td>\n",
       "      <td>0.055845</td>\n",
       "      <td>POLYGON ((94.94575 26.93518, 94.9551 26.93975,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>NAGALAND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MON</td>\n",
       "      <td>43</td>\n",
       "      <td>Tapi</td>\n",
       "      <td>1</td>\n",
       "      <td>NAGALAND</td>\n",
       "      <td>1301</td>\n",
       "      <td>Pre delimitation</td>\n",
       "      <td>1.056157</td>\n",
       "      <td>0.030387</td>\n",
       "      <td>POLYGON ((95.22324 26.75964, 95.2176 26.75589,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>NAGALAND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MON</td>\n",
       "      <td>42</td>\n",
       "      <td>Wakching</td>\n",
       "      <td>1</td>\n",
       "      <td>NAGALAND</td>\n",
       "      <td>1301</td>\n",
       "      <td>Pre delimitation</td>\n",
       "      <td>0.980303</td>\n",
       "      <td>0.018828</td>\n",
       "      <td>POLYGON ((94.86775 26.82831, 94.87219 26.82334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>NAGALAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TUENSANG</td>\n",
       "      <td>49</td>\n",
       "      <td>Tamlu</td>\n",
       "      <td>1</td>\n",
       "      <td>NAGALAND</td>\n",
       "      <td>1301</td>\n",
       "      <td>Pre delimitation</td>\n",
       "      <td>1.133296</td>\n",
       "      <td>0.021899</td>\n",
       "      <td>POLYGON ((94.73863 26.76868, 94.74029 26.77594...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>NAGALAND</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MOKOKCHUNG</td>\n",
       "      <td>21</td>\n",
       "      <td>Tuli</td>\n",
       "      <td>1</td>\n",
       "      <td>NAGALAND</td>\n",
       "      <td>1301</td>\n",
       "      <td>Pre delimitation</td>\n",
       "      <td>0.965989</td>\n",
       "      <td>0.022397</td>\n",
       "      <td>POLYGON ((94.73863 26.76868, 94.73627 26.74956...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  ST_CODE   ST_NAME  DT_CODE   DIST_NAME  AC_NO   AC_NAME  PC_NO  \\\n",
       "0         1       13  NAGALAND      1.0         MON     41     Tizit      1   \n",
       "1         1       13  NAGALAND      1.0         MON     43      Tapi      1   \n",
       "2         1       13  NAGALAND      1.0         MON     42  Wakching      1   \n",
       "3         1       13  NAGALAND      2.0    TUENSANG     49     Tamlu      1   \n",
       "4         1       13  NAGALAND      3.0  MOKOKCHUNG     21      Tuli      1   \n",
       "\n",
       "    PC_NAME  PC_ID            STATUS  Shape_Leng  Shape_Area  \\\n",
       "0  NAGALAND   1301  Pre delimitation    1.381854    0.055845   \n",
       "1  NAGALAND   1301  Pre delimitation    1.056157    0.030387   \n",
       "2  NAGALAND   1301  Pre delimitation    0.980303    0.018828   \n",
       "3  NAGALAND   1301  Pre delimitation    1.133296    0.021899   \n",
       "4  NAGALAND   1301  Pre delimitation    0.965989    0.022397   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((94.94575 26.93518, 94.9551 26.93975,...  \n",
       "1  POLYGON ((95.22324 26.75964, 95.2176 26.75589,...  \n",
       "2  POLYGON ((94.86775 26.82831, 94.87219 26.82334...  \n",
       "3  POLYGON ((94.73863 26.76868, 94.74029 26.77594...  \n",
       "4  POLYGON ((94.73863 26.76868, 94.73627 26.74956...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Shapefile\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Load the shapefile\n",
    "shapefile = gpd.read_file(\"data/India_AC.shp\")\n",
    "\n",
    "shapefile.info()\n",
    "shapefile.head()\n",
    "\n",
    "# Print unique values for the specified columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9bd6b0-ff4c-44bd-9797-12753e4aa888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d55f7a-7640-4c1e-bdd5-711b3751a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31406df-0b89-4652-8f6d-8d10965c44c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c57bbb-c352-4042-a255-4badb23d60e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82987c-00cd-4aa4-b22c-98fd03196e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85588a-3f5c-4f14-84ff-74078f6559d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b4059c-ed9f-447a-8976-a26a12244157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938f0d7-f776-4185-b77a-b4ce9ac424fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b431f49-c828-4514-9c78-f813a0872edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf42c7-cc92-4e9f-848b-a009d39cbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Public Sector Employment:\n",
    "Measuring the size of public sector employment, which could indicate patronage networks tied to corruption.\n",
    "- ec13_emp_gov: Total employment in public sector jobs.\n",
    "\n",
    "source: ec13_con08\n",
    "\"\"\"\n",
    "\n",
    "public_employment_dataset = process_dataset('ec13_con08.csv', ['ec13_emp_gov'], 'ac08_id')\n",
    "public_employment_dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
